{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IBM Quantum Challenge Fall 2021\n",
    "\n",
    "# Challenge 3: 量子機械学習による画像分類"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='problem'></div>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "Quantum Challengeに最適な環境で取り組んでいただくために、右上のアカウントメニューより **light** モードを選択されることをお勧めします。",
	"</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## はじめに\n",
    "\n",
    "機械学習技術は，近年その高い性能と汎用性の高さから非常に注目を集めています。実際，アルゴリズムの発展や計算資源の増大に伴って，様々な産業において実用化が進められています。その代表例の一つは画像認識です。機械学習によって人間と同等以上の精度で画像を分類できるようになっています。これにより，例えば衣料画像の自動分類が可能となり，アパレル分野におけるネットショッピングがより便利になりました。\n",
    "\n",
    "量子計算を機械学習に応用することによって，その性能を更に向上することができる可能性が近年示されています。このような枠組みを量子機械学習と呼び，量子サポートベクターマシン (QSVM) や量子敵対的生成ネットワーク (QGAN) など，様々なアルゴリズムが提案されています。このチャレンジでは， QSVMを用いて衣料画像の画像分類に取り組みます。\n",
    "\n",
    "QSVMは，代表的な古典機械学習アルゴリズムの一つであるサポートベクターマシン (SVM) に量子計算を適用したもので押す。一口にQSVMといっても様々なアプローチが存在し，誤り耐性量子計算を前提として計算の高速化を目指すものや，現在のノイズありデバイスを想定して表現力の向上を目指すものなどがあります。今回のチャレンジは後者に注目したものとなっています。\n",
    "\n",
    "今回扱うQSVMの実装では，量子部分をどのように構成するか，具体的には特徴マップの構成について工夫することが可能です。これは，複雑な特徴マップはより大きな表現力が期待される一方で，ノイズの影響をより受けやすくなるというトレードオフが存在するためで，そのバランスを考慮して構成を考える必要があります。特にノイズを多く含むデバイスを利用する場合に，この点は非常に重要となってきます。\n",
    "\n",
    "このチャレンジで登場する概念の多くは，2021 Qiskit Global Summer School (QGSS) で解説されています。教材や講義動画は公開されているので，それらも合わせて学習することが推奨されます。各パートで対応する講義動画のリンクを付記してあるので，参考にしてください。\n",
    "\n",
    "<center><div><img src=\"./resources/ecommerce.jpg\" width=\"640\" /></div></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "**目標**\n",
    "\n",
    "多クラス分類タスクに対してQSVMを実装し，正確に画像を分類してください.\n",
    "    \n",
    "**構成**\n",
    "\n",
    "初めに，単純なデータセットの二値分類を題材として，QSVMをどのように構成するか学びます。次に，それを別のデータセットの3クラス分類というより複雑な問題設定に適用します。\n",
    "\n",
    "**1. チュートリアル - QSVMによるMNIST二値分類:** QSVMの典型的なワークフローを学びましょう。\n",
    "\n",
    "**2. チャレンジ - QSVMによるFashion-MNIST多値分類:** QSVMの２クラス分類器を用いて，3クラス分類器を実装しましょう。次元と特徴マップを調整することによって，より小さい特徴マップ回路によって高い正解率を達成しましょう。\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "このChallengeを始める前に、QSVMをつかった分類について学ぶために [**Qiskit Machine Learning Demo Session with Anton Dekusar**](https://youtu.be/claoY57eVIc?t=1814) と [**demo notebook**](https://github.com/qiskit-community/qiskit-application-modules-demo-sessions/tree/main/qiskit-machine-learning) をご覧になることをお勧めします。\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import gzip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import cm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# scikit-learn imports\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Qiskit imports\n",
    "from qiskit import Aer, execute\n",
    "from qiskit.circuit import QuantumCircuit, Parameter, ParameterVector\n",
    "from qiskit.circuit.library import PauliFeatureMap, ZFeatureMap, ZZFeatureMap\n",
    "from qiskit.circuit.library import TwoLocal, NLocal, RealAmplitudes, EfficientSU2\n",
    "from qiskit.circuit.library import HGate, RXGate, RYGate, RZGate, CXGate, CRXGate, CRZGate\n",
    "from qiskit_machine_learning.kernels import QuantumKernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: チュートリアル - QSVMによるMNIST二値分類\n",
    "\n",
    "このパートでは，QSVMによって手書き数字の4と9を分類します。このチュートリアルを通して，QSVMを二値分類に適用するワークフローについて学びましょう。\n",
    "\n",
    "QGSS教材:\n",
    "- Lab 3: https://www.youtube.com/watch?v=GVhCOTzAkCM&list=PLOFEBzvs-VvqJwybFxkTiDzhf5E11p8BI&index=17\n",
    "\n",
    "### 1. データの準備\n",
    "\n",
    "ここで扱うデータは，MNISTという有名な手書き数字画像データセットの一部です。このサブセットは手書き数字の\"4\"と\"9\"からなっており，ここではそれらの分類に取り組みます。\n",
    "\n",
    "このデータセットは，80個のラベル付き訓練データと20個のラベル無しテストデータの，計100データからなります。各データは，28×28の手書き数字データ画像を配列にしたもので，それぞれの値は0 (白) から255 (黒) までの整数となっています。このようなデータセットをQSVMによって分類するためには，まず値を-1から1の間にスケーリングし，その次元を量子ビットの数まで圧縮する必要があります。(ここでは5次元としています)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "DATA_PATH = './resources/ch3_part1.npz'\n",
    "data = np.load(DATA_PATH)\n",
    "\n",
    "sample_train = data['sample_train']\n",
    "labels_train = data['labels_train']\n",
    "sample_test = data['sample_test']\n",
    "\n",
    "# Split train data\n",
    "sample_train, sample_val, labels_train, labels_val = train_test_split(\n",
    "    sample_train, labels_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Visualize samples\n",
    "fig = plt.figure()\n",
    "\n",
    "LABELS = [4, 9]\n",
    "num_labels = len(LABELS)\n",
    "for i in range(num_labels):\n",
    "    ax = fig.add_subplot(1, num_labels, i+1)\n",
    "    img = sample_train[labels_train==LABELS[i]][0].reshape((28, 28))\n",
    "    ax.imshow(img, cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize\n",
    "ss = StandardScaler()\n",
    "sample_train = ss.fit_transform(sample_train)\n",
    "sample_val = ss.transform(sample_val)\n",
    "sample_test = ss.transform(sample_test)\n",
    "\n",
    "# Reduce dimensions\n",
    "N_DIM = 5\n",
    "pca = PCA(n_components=N_DIM)\n",
    "sample_train = pca.fit_transform(sample_train)\n",
    "sample_val = pca.transform(sample_val)\n",
    "sample_test = pca.transform(sample_test)\n",
    "\n",
    "# Normalize\n",
    "mms = MinMaxScaler((-1, 1))\n",
    "sample_train = mms.fit_transform(sample_train)\n",
    "sample_val = mms.transform(sample_val)\n",
    "sample_test = mms.transform(sample_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. データのエンコーディング\n",
    "\n",
    "次に，古典的なデータを量子特徴マップによって状態空間にエンコードしていきます。どの特徴マップを使用するの選択は重要であり，扱うデータセットに依存します。ここでは，Qiskitに用意されている特徴マップを確認し，選択・調整できるようになることを目指します。\n",
    "\n",
    "### 2.1 量子特徴マップ\n",
    "\n",
    "量子特徴マップ $\\phi(\\mathbf{x})$ とはその名の通り，古典的な特徴ベクトル $\\mathbf{x}$ から量子状態 $|\\Phi(\\mathbf{x})\\rangle\\langle\\Phi(\\mathbf{x})|$ への写像です。これは，初期状態 $|0\\rangle^{n}$ (_n_ はエンコーディングに使われる量子ビット数) にユニタリー演算 $|0\\rangle^{n}$ を適用することによって実現します。\n",
    "\n",
    "現在Qiskitで利用可能な以下の特徴マップは，[**_Havlicek et al_.  Nature **567**, 209-212 (2019)**](https://www.nature.com/articles/s41586-019-0980-2) で紹介されているものです。特に `ZZFeatureMap` は古典的にシミュレートすることが難しく，小中規模な量子デバイス上でも実装できると見込まれています。\n",
    "\n",
    "- [**`PauliFeatureMap`**](https://qiskit.org/documentation/stubs/qiskit.circuit.library.PauliFeatureMap.html)\n",
    "- [**`ZZFeatureMap`**](https://qiskit.org/documentation/stubs/qiskit.circuit.library.ZFeatureMap.html)\n",
    "- [**`ZFeatureMap`**](https://qiskit.org/documentation/stubs/qiskit.circuit.library.ZZFeatureMap.html)\n",
    "\n",
    "`PauliFeatureMap`は以下のように使用できます。\n",
    "\n",
    "```python\n",
    "PauliFeatureMap(feature_dimension=None, reps=2, \n",
    "                entanglement='full', paulis=None, \n",
    "                data_map_func=None, parameter_prefix='x',\n",
    "                insert_barriers=False)\n",
    "```\n",
    "\n",
    "ユニタリ演算子は以下のように記述されます。\n",
    "\n",
    "$$ \\mathcal{U}_{\\Phi(\\mathbf{x})}=\\prod_d U_{\\Phi(\\mathbf{x})}H^{\\otimes n},\\ U_{\\Phi(\\mathbf{x})}=\\exp\\left(i\\sum_{S\\subseteq[n]}\\phi_S(\\mathbf{x})\\prod_{k\\in S} P_i\\right), $$\n",
    "\n",
    "これは以下の回路図に示すように，エンタングルメントを生成するブロック $U_{\\Phi(\\mathbf{x})}$ とアダマールゲートの層が交互に連なった形をしています。\n",
    "\n",
    "<div><img src=\"./resources/featuremap.png\" width=\"1000\" /></div>\n",
    "\n",
    "各エンタングルメント生成ブロック $U_{\\Phi(\\mathbf{x})}$ の中で， $P_i \\in \\{ I, X, Y, Z \\}$はパウリ行列を表し，添字 $S$ は量子ビット間の接続に対応しています。 ($S \\in \\{\\binom{n}{k}\\,\\ k = 1,... n \\}$) デフォルトでデータのマッピング関数 $\\phi_S(\\mathbf{x})$ は以下のようになっています。\n",
    "\n",
    "$$\\phi_S:\\mathbf{x}\\mapsto \\Bigg\\{\\begin{array}{ll}\n",
    "    x_i & \\mbox{if}\\ S=\\{i\\} \\\\\n",
    "        (\\pi-x_i)(\\pi-x_j) & \\mbox{if}\\ S=\\{i,j\\}\n",
    "    \\end{array}$$\n",
    "\n",
    "$k = 1, P_0 = Z$のときに，これは`ZFeatureMap`となります。\n",
    "\n",
    "$$\\mathcal{U}_{\\Phi(\\mathbf{x})} = \\left( \\exp\\left(i\\sum_j \\phi_{\\{j\\}}(\\mathbf{x}) \\, Z_j\\right) \\, H^{\\otimes n} \\right)^d.$$\n",
    "\n",
    "これは以下のように使用できます。\n",
    "```python\n",
    "ZFeatureMap(feature_dimension, reps=2, \n",
    "            data_map_func=None, insert_barriers=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 features, depth 2\n",
    "map_z = ZFeatureMap(feature_dimension=3, reps=2)\n",
    "map_z.decompose().draw('mpl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この特徴マップはエンタングルメントを伴わないことから，古典的なシミュレーションが容易であり，量子的な優位性が得られないことに注意してください。\n",
    "\n",
    "$k = 2, P_0 = Z, P_1 = ZZ$のとき，`ZZFeatureMap`となります。\n",
    "$$\\mathcal{U}_{\\Phi(\\mathbf{x})} = \\left( \\exp\\left(i\\sum_{jk} \\phi_{\\{j,k\\}}(\\mathbf{x}) \\, Z_j \\otimes Z_k\\right) \\, \\exp\\left(i\\sum_j \\phi_{\\{j\\}}(\\mathbf{x}) \\, Z_j\\right) \\, H^{\\otimes n} \\right)^d.$$ \n",
    "\n",
    "これは以下のように使用できます。\n",
    "```python\n",
    "ZZFeatureMap(feature_dimension, reps=2, \n",
    "             entanglement='full', data_map_func=None, \n",
    "             insert_barriers=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 features, depth 1, linear entanglement\n",
    "map_zz = ZZFeatureMap(feature_dimension=3, reps=1, entanglement='linear')\n",
    "map_zz.decompose().draw('mpl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この特徴マップにはエンタングルメントが含まれており，その形を以下のように変更することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 features, depth 1, circular entanglement\n",
    "map_zz = ZZFeatureMap(feature_dimension=3, reps=1, entanglement='circular')\n",
    "map_zz.decompose().draw('mpl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特徴マップ中のパウリゲートをカスタマイズすることも可能です。例えば $P_0 = X, P_1 = Y, P_2 = ZZ$ とする場合は以下のようになります。\n",
    "\n",
    "$$\\mathcal{U}_{\\Phi(\\mathbf{x})} = \\left( \\exp\\left(i\\sum_{jk} \\phi_{\\{j,k\\}}(\\mathbf{x}) \\, Z_j \\otimes Z_k\\right) \\, \\exp\\left(i\\sum_{j} \\phi_{\\{j\\}}(\\mathbf{x}) \\, Y_j\\right) \\, \\exp\\left(i\\sum_j \\phi_{\\{j\\}}(\\mathbf{x}) \\, X_j\\right) \\, H^{\\otimes n} \\right)^d.$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 features, depth 1\n",
    "map_pauli = PauliFeatureMap(feature_dimension=3, reps=1, paulis = ['X', 'Y', 'ZZ'])\n",
    "map_pauli.decompose().draw('mpl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "パラメータ付き回路を特徴マップとして用いるためには，[`NLocal`](https://qiskit.org/documentation/stubs/qiskit.circuit.library.NLocal.html) と [`TwoLocal`](https://qiskit.org/documentation/stubs/qiskit.circuit.library.TwoLocal.html) を利用することができます。\n",
    "\n",
    "```python\n",
    "TwoLocal(num_qubits=None, reps=3, rotation_blocks=None, \n",
    "         entanglement_blocks=None, entanglement='full',  \n",
    "         skip_unentangled_qubits=False, \n",
    "         skip_final_rotation_layer=False, \n",
    "         parameter_prefix='θ', insert_barriers=False, \n",
    "         initial_state=None)\n",
    "```\n",
    "\n",
    "```python\n",
    "NLocal(num_qubits=None, reps=1, rotation_blocks=None, \n",
    "       entanglement_blocks=None, entanglement=None,   \n",
    "       skip_unentangled_qubits=False, \n",
    "       skip_final_rotation_layer=False, \n",
    "       overwrite_block_parameters=True, \n",
    "       parameter_prefix='θ', insert_barriers=False, \n",
    "       initial_state=None, name='nlocal')\n",
    "```\n",
    "\n",
    "どちらも，ローテーション層とエンタングルメント層を交互に繰り返すパラメータ付き回路を作成します。`NLocal` では各ブロックが任意のサイズとできる一方で，`TwoLocal`ではローテーション層は一量子ビットゲート，エンタングルメント層は2量子ビットゲートに限定されます。\n",
    "\n",
    "例えば以下は `TwoLocal` の回路で，回転層に$R_y$と$R_Z$ゲート，エンタングルメント層に $CX$ゲートを用いて，循環的なエンタングルメントを実現しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twolocal = TwoLocal(num_qubits=3, reps=2, rotation_blocks=['ry','rz'], \n",
    "               entanglement_blocks='cx', entanglement='circular', insert_barriers=True)\n",
    "twolocal.decompose().draw('mpl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同じものは，`NLocal`で以下のように実現できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twolocaln = NLocal(num_qubits=3, reps=2,\n",
    "               rotation_blocks=[RYGate(Parameter('a')), RZGate(Parameter('a'))], \n",
    "               entanglement_blocks=CXGate(), \n",
    "               entanglement='circular', insert_barriers=True)\n",
    "twolocaln.decompose().draw('mpl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それでは，1個目の訓練データを `PauliFeatureMap`によってエンコードしてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'First training data: {sample_train[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_map = PauliFeatureMap(feature_dimension=N_DIM, reps=1, paulis = ['X', 'Y', 'ZZ'])\n",
    "encode_circuit = encode_map.bind_parameters(sample_train[0])\n",
    "encode_circuit.decompose().draw(output='mpl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</div>\n",
    "    \n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<b>Challenge 3a</b> \n",
    "\n",
    "5次元データをエンコードする特徴マップを，3回の繰り返しと'circular'型のエンタングルメントを伴う`ZZFeatureMap`によって構成してください。(ただし繰り返し数とエンタングルメントの種類の他は，デフォルト設定のままとしてください)\n",
    "    \n",
    "</div>\n",
    "\n",
    "提出フォーマット:\n",
    "```python\n",
    "ex3a_fmap = ZZFeatureMap(...)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# Provide your code here\n",
    "\n",
    "\n",
    "ex3a_fmap = \n",
    "\n",
    "\n",
    "\n",
    "##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 答えを確認して以下のコードで提出します\n",
    "from qc_grader import grade_ex3a\n",
    "grade_ex3a(ex3a_fmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 量子カーネル推定\n",
    "\n",
    "量子特徴マップ $\\phi(\\mathbf{x})$ から量子カーネル $k(\\mathbf{x}_i,\\mathbf{x}_j)= \\phi(\\mathbf{x}_j)^\\dagger\\phi(\\mathbf{x}_i)$ を考えることができます。これは $\\mathbf{x}_i$ と $\\mathbf{x}_j$ が近いときにより大きな値となることから，類似性の尺度として見ることができます。\n",
    "\n",
    "有限次元のデータを考える際には，この量子カーネルを行列 $K_{ij} = \\left| \\langle \\phi^\\dagger(\\mathbf{x}_j)| \\phi(\\mathbf{x}_i) \\rangle \\right|^{2}$ として表すことができます。このカーネル行列の各要素は，量子コンピュータ上で遷移確率を測定することにより，計算することが可能です。\n",
    "\n",
    "$$\n",
    "\\left| \\langle \\phi^\\dagger(\\mathbf{x}_j)| \\phi(\\mathbf{x}_i) \\rangle \\right|^{2} = \n",
    "\\left| \\langle 0^{\\otimes n} | \\mathbf{U_\\phi^\\dagger}(\\mathbf{x}_j) \\mathbf{U_\\phi}(\\mathbf{x_i}) | 0^{\\otimes n} \\rangle \\right|^{2}\n",
    "$$\n",
    "\n",
    "ここで特徴マップとしては，$n$量子ビットに対するユニタリー変換 $\\mathbf{U_\\phi}(\\mathbf{x})$ として記述されるパラメータ付き回路を仮定しています。\n",
    "\n",
    "これにより，量子カーネル行列の推定値を得ることができ，サポートベクターマシンなどのカーネル機械学習アルゴリズムに利用することができます。\n",
    "\n",
    "[***Havlicek et al*.  Nature 567, 209-212 (2019)**](https://www.nature.com/articles/s41586-019-0980-2)で議論されているように，量子カーネルに基づくアルゴリズムは，その量子カーネルを古典的に推定するのが難しい場合にのみ，古典的な手法に対して優位性をもつ可能性があります。また古典的に量子カーネルを推定することの難しさは，量子優位性を得るための必要条件に過ぎず，十分条件ではありません。\n",
    "\n",
    "しかし，[***Liu et al.* arXiv:2010.02174 (2020)**](https://arxiv.org/abs/2010.02174)では，全ての古典的な学習器に対して量子優位性をもつような問題の存在が示されました。\n",
    "\n",
    "データの前準備ができたら，PauliFeatureMapを使って`QuantumKernel`クラスを設定し，`BasicAer``statevector_simulator`を用いてカーネル行列を推定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pauli_map = PauliFeatureMap(feature_dimension=N_DIM, reps=1, paulis = ['X', 'Y', 'ZZ'])\n",
    "pauli_kernel = QuantumKernel(feature_map=pauli_map, quantum_instance=Aer.get_backend('statevector_simulator'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "カーネル行列の成分の一つである，1個目と2個目の訓練データ間の遷移確率を算出してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'First training data : {sample_train[0]}')\n",
    "print(f'Second training data: {sample_train[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず回路を作成して，描画してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pauli_circuit = pauli_kernel.construct_circuit(sample_train[0], sample_train[1])\n",
    "pauli_circuit.decompose().decompose().draw(output='mpl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回路が左右対称になっていて，一方がデータの片方を，もう一方がデータのもう片方をエンコードしていることに注目してください。\n",
    "\n",
    "次に，この回路のシミュレーションを行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = Aer.get_backend('qasm_simulator')\n",
    "job = execute(pauli_circuit, backend, shots=8192, \n",
    "              seed_simulator=1024, seed_transpiler=1024)\n",
    "counts = job.result().get_counts(pauli_circuit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "遷移確率は，ゼロ状態のカウント数の割合として得られます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Transition amplitude: {counts['0'*N_DIM]/sum(counts.values())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このプロセスを，訓練データの組ごとに繰り返して訓練カーネル行列を埋め，訓練データとテストデータの組ごとに繰り返してテストカーネル行列を埋めます。なお各行列は対称行列になるので，計算時間を短縮するために要素の半分だけを計算します。\n",
    "\n",
    "ここでは，訓練カーネル行列とテストカーネル行列を計算し，プロットしています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_train = pauli_kernel.evaluate(x_vec=sample_train)\n",
    "matrix_val = pauli_kernel.evaluate(x_vec=sample_val, y_vec=sample_train)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].imshow(np.asmatrix(matrix_train),\n",
    "              interpolation='nearest', origin='upper', cmap='Blues')\n",
    "axs[0].set_title(\"training kernel matrix\")\n",
    "axs[1].imshow(np.asmatrix(matrix_val),\n",
    "              interpolation='nearest', origin='upper', cmap='Reds')\n",
    "axs[1].set_title(\"validation kernel matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</div>\n",
    "    \n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<b>Challenge 3b</b> \n",
    "\n",
    "$x = (-0.5, -0.4, 0.3, 0, -0.9)$ と $y = (0, -0.7, -0.3, 0, -0.4)$ の間の遷移確率を，繰り返し3回・エンタングルメント'circular'の'ZZFeatureMap'を用いて計算してください。(ただし繰り返し数とエンタングルメントの種類の他は，デフォルト設定のままとしてください) また 'shots=8192', 'seed_simulator=1024', 'seed_transpiler=1024' の 'qasm_simulator' でシミュレートしてください。\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [-0.5, -0.4, 0.3, 0, -0.9]\n",
    "y = [0, -0.7, -0.3, 0, -0.4]\n",
    "\n",
    "##############################\n",
    "# Provide your code here\n",
    "\n",
    "\n",
    "ex3b_amp = \n",
    "\n",
    "\n",
    "##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 答えを確認して以下のコードで提出します\n",
    "from qc_grader import grade_ex3b\n",
    "grade_ex3b(ex3b_amp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QGSS教材:\n",
    "- [**Kernel Trick (Lecture 6.1)**](https://www.youtube.com/watch?v=m6EzmYsEOiI&list=PLOFEBzvs-VvqJwybFxkTiDzhf5E11p8BI&index=14)\n",
    "- [**Kernel Trick (Lecture 6.2)**](https://www.youtube.com/watch?v=zw3JYUrS-v8&list=PLOFEBzvs-VvqJwybFxkTiDzhf5E11p8BI&index=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 量子サポートベクターマシン (QSVM)\n",
    "\n",
    "[***Havlicek et al*.  Nature 567, 209-212 (2019)**](https://www.nature.com/articles/s41586-019-0980-2)で提案された，量子カーネルサポートベクター分類アルゴリズムは，以下のステップから構成されています。\n",
    "\n",
    "<div><img src=\"./resources/qsvc.png\" width=\"1000\"></div> \n",
    "\n",
    "1. 量子カーネル行列を訓練用とテスト用それぞれで構築する。\n",
    "    1. 訓練データの各ペア　$\\mathbf{x}_{i},\\mathbf{x}_j$ で，特徴マップを適用し，遷移確率を測定する。 $ K_{ij} = \\left| \\langle 0 | \\mathbf{U}^\\dagger_{\\Phi(\\mathbf{x_j})} \\mathbf{U}_{\\Phi(\\mathbf{x_i})} | 0 \\rangle \\right|^2 $\n",
    "    2. 訓練データ $\\mathbf{x_i} $とテストデータ $\\mathbf{y_j}$ の各ペアで，特徴マップを適用し，遷移確率を測定する。$ K_{ij} = \\left| \\langle 0 | \\mathbf{U}^\\dagger_{\\Phi(\\mathbf{y_j})} \\mathbf{U}_{\\Phi(\\mathbf{x_i})} | 0 \\rangle \\right|^2 $\n",
    "2. 量子カーネル行列を古典的なサポートベクターマシン分類アルゴリズムで使用する。\n",
    "\n",
    "`scikit-learn`の`svc`アルゴリズムでは，二つの方法でカーネルを定義することができます。 [**define a custom kernel**](https://scikit-learn.org/stable/modules/svm.html#custom-kernels) 一つはカーネルを呼び出し可能な関数として提供する方法で，もう一つはカーネル行列を事前に計算しておく方法です。どちらもQiskitの`QuantumKernel`クラスを適用することができます。\n",
    "\n",
    "以下のコードは，先に計算した訓練用とテスト用のカーネル行列を受け取り，`scikit-learn`の`svc`アルゴリズムに提供しています："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pauli_svc = SVC(kernel='precomputed')\n",
    "pauli_svc.fit(matrix_train, labels_train)\n",
    "pauli_score = pauli_svc.score(matrix_val, labels_val)\n",
    "\n",
    "print(f'Precomputed kernel classification test score: {pauli_score*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QGSS教材:\n",
    "- [**Classical SVM (Lecture 4.2)**](https://www.youtube.com/watch?v=lpPij21jnZ4&list=PLOFEBzvs-VvqJwybFxkTiDzhf5E11p8BI&index=9)\n",
    "- [**Quantum Classifier (Lecture 5.1)**](https://www.youtube.com/watch?v=-sxlXNz7ZxU&list=PLOFEBzvs-VvqJwybFxkTiDzhf5E11p8BI&index=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: チャレンジ - QSVMによるFashion-MNIST多値分類\n",
    "\n",
    "このパートでは，これまでに学んだことを活用して，衣料画像の3クラス分類を実装し，その精度を向上を目指します。\n",
    "\n",
    "</div>\n",
    "    \n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<b>Challenge 3c</b> \n",
    "\n",
    "**目標**: 衣料画像データセットに対し，できるだけ小さい特徴マップ回路で，70%の正解率を達成する3クラス分類モデルをQSVMによって実装してください。\n",
    "\n",
    "**データセット**: Fashion-MNIST 衣料画像データセット。今回の課題では，以下3つのデータセットが用意されています。\n",
    "- 訓練データ: 画像とラベルの両方が与えられています。\n",
    "- 公開テストデータ: 画像が与えられ，ラベルは与えられていません。\n",
    "- 非公開テストデータ: 画像とラベルの両方が隠されています。\n",
    "    \n",
    "採点は公開テストデータと非公開テストデータの両方に対して行われます。これは量子的な手法が用いられていることを確認し，不正を防ぐためです。\n",
    "    \n",
    "</div>\n",
    "\n",
    "### 二値分類モデルを用いた多値分類モデルの実装\n",
    "\n",
    "ここまでは，QSVMによる二値分類の実装方法を学びました。では，これを多値分類に拡張するにはどうすればよいでしょうか。それには，2つのアプローチがあります。一つは \"One-vs-Rest (一対他)\" アプローチで，もう一つは \"One-vs-One (一対一)\" アプローチです。\n",
    "\n",
    "1. One-vs-Rest: このアプローチでは，あるクラスをpositive，他のクラスをnegativeとして分類する二値分類モデルを各クラスについて構築し，それらを組み合わせることによって多値分類を実現します。各クラスに1つの分類モデルが必要なので，Nクラス分類にはN個の分類モデルが必要となります。このアプローチは，必要な分類モデルが少なく済むというメリットがある一方で，それぞれの二値分類においてラベルが不均衡になるというデメリットがあります。\n",
    "2. One-vs-One: このアプローチでは，ある2クラスをpositiveとnegativeに分類する二値分類モデルをクラスの組ごとに構築し，それらを組み合わせることで多値分類を実現します。各ラベルの組に対して1つの二値分類モデルが必要なので，Nクラス分類には N(N-1)/2\n",
    "個の分類モデルが必要となります。このアプローチは，各二値分類でラベルが不均衡になりにくいというメリットがある一方で，必要な分類モデルが多くなってしまうというデメリットがあります。\n",
    "\n",
    "どちらのアプローチでも今回の問題を解くことができますが，ここではOne-vs-Restアプローチに則った誘導が与えられています。誘導に沿って取り組んでください。\n",
    "\n",
    "<div><img src=\"./resources/onevsrest.png\" width=\"800\"></div>\n",
    "\n",
    "Figure via [cc.gatech.edu](https://www.cc.gatech.edu/classes/AY2016/cs4476_fall/results/proj4/html/jnanda3/index.html)\n",
    "\n",
    "### 1. データの準備\n",
    "ここで扱うデータは，MNISTデータセットの亜種であるFashion-MNISTという衣料画像データセットのサブセットです。以下のラベルの画像が含まれています。\n",
    "\n",
    "- label 0: Tシャツ\n",
    "- label 2: プルオーバー\n",
    "- label 3: ドレス\n",
    "\n",
    "まずデータセットを読み込んで，クラスごとに1枚ずつ画像を表示してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "DATA_PATH = './resources/ch3_part2.npz'\n",
    "data = np.load(DATA_PATH)\n",
    "\n",
    "sample_train = data['sample_train']\n",
    "labels_train = data['labels_train']\n",
    "sample_test = data['sample_test']\n",
    "\n",
    "# Split train data\n",
    "sample_train, sample_val, labels_train, labels_val = train_test_split(\n",
    "    sample_train, labels_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Visualize samples\n",
    "fig = plt.figure()\n",
    "\n",
    "LABELS = [0, 2, 3]\n",
    "num_labels = len(LABELS)\n",
    "for i in range(num_labels):\n",
    "    ax = fig.add_subplot(1, num_labels, i+1)\n",
    "    img = sample_train[labels_train==LABELS[i]][0].reshape((28, 28))\n",
    "    ax.imshow(img, cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に，チュートリアルと同様に以下のデータセットの前処理をします\n",
    "\n",
    "- 標準化\n",
    "- 主成分分析(PCA)による次元圧縮\n",
    "- 正規化\n",
    "\n",
    "なおN_DIMを変えることで，次元数を変えることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize\n",
    "standard_scaler = StandardScaler()\n",
    "sample_train = standard_scaler.fit_transform(sample_train)\n",
    "sample_val = standard_scaler.transform(sample_val)\n",
    "sample_test = standard_scaler.transform(sample_test)\n",
    "\n",
    "# Reduce dimensions\n",
    "N_DIM = 5\n",
    "pca = PCA(n_components=N_DIM)\n",
    "sample_train = pca.fit_transform(sample_train)\n",
    "sample_val = pca.transform(sample_val)\n",
    "sample_test = pca.transform(sample_test)\n",
    "\n",
    "# Normalize\n",
    "min_max_scaler = MinMaxScaler((-1, 1))\n",
    "sample_train = min_max_scaler.fit_transform(sample_train)\n",
    "sample_val = min_max_scaler.transform(sample_val)\n",
    "sample_test = min_max_scaler.transform(sample_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. モデリング\n",
    "\n",
    "One-vs-Restアプローチに基づき，以下3つのQSVM二値分類モデルを作成しましょう。\n",
    "- ラベル0 vs それ以外\n",
    "- ラベル2 vs それ以外\n",
    "- ラベル3 vs それ以外\n",
    "\n",
    "ここでは，第一の二値分類モデルの実装をヒントとして示します。\n",
    "\n",
    "### 2.1: ラベル0 vs それ以外\n",
    "ラベル0をpositive (1)，それ以外をnegative (0) とした新しいラベルを以下のように作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train_0 = np.where(labels_train==0, 1, 0)\n",
    "labels_val_0 = np.where(labels_val==0, 1, 0)\n",
    "\n",
    "print(f'Original validation labels:      {labels_val}')\n",
    "print(f'Validation labels for 0 vs Rest: {labels_val_0}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "元々のラベルが0だった場所だけが1となっていることを確認してください。\n",
    "\n",
    "次に，チュートリアルと同様にQSVMによって二値分類モデルを構築します。なお，このヒントではPauliFeatureMapを使用していますが，別の特徴マップを使用しても構いません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pauli_map_0 = PauliFeatureMap(feature_dimension=N_DIM, reps=2, paulis = ['X', 'Y', 'ZZ'])\n",
    "pauli_kernel_0 = QuantumKernel(feature_map=pauli_map_0, quantum_instance=Aer.get_backend('statevector_simulator'))\n",
    "\n",
    "pauli_svc_0 = SVC(kernel='precomputed', probability=True)\n",
    "\n",
    "matrix_train_0 = pauli_kernel_0.evaluate(x_vec=sample_train)\n",
    "pauli_svc_0.fit(matrix_train_0, labels_train_0)\n",
    "\n",
    "matrix_val_0 = pauli_kernel_0.evaluate(x_vec=sample_val, y_vec=sample_train)\n",
    "pauli_score_0 = pauli_svc_0.score(matrix_val_0, labels_val_0)\n",
    "print(f'Accuracy of discriminating between label 0 and others: {pauli_score_0*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QSVMの二値分類モデルは，ラベル0とそれ以外を一定の確率で区別できていることが分かります。\n",
    "\n",
    "最後に各テストデータについてラベルが0である確率を計算します。これは``predict_proba``メソッドで求められます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_test_0 = pauli_kernel_0.evaluate(x_vec=sample_test, y_vec=sample_train)\n",
    "pred_0 = pauli_svc_0.predict_proba(matrix_test_0)[:, 1]\n",
    "print(f'Probability of label 0: {np.round(pred_0, 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このようにして得られた確率は，多値分類において重要な手がかりとなります。\n",
    "\n",
    "残り2つのラベルについても，同様に確率を求めます。\n",
    "\n",
    "### 2.2: ラベル2 vs それ以外\n",
    "QSVMを用いて二値分類モデルを構築し，各テストデータについてラベルが2である確率を計算してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# Provide your code here\n",
    "\n",
    "pred_2 = \n",
    "\n",
    "\n",
    "\n",
    "##############################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 ラベル3 vs それ以外\n",
    "QSVMを用いて二値分類モデルを構築し，各テストデータについてラベルが3である確率を計算してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# Provide your code here\n",
    "\n",
    "pred_3 = \n",
    "\n",
    "\n",
    "\n",
    "##############################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 予測\n",
    "\n",
    "最後に，各ラベルの確率に基づいて最終的な予測を行います。予測は以下の形式としてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_pred = np.load('./resources/ch3_part2_sub.npy')\n",
    "print(f'Sample prediction: {sample_pred}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多値分類の予測方法を理解するために，まずはラベル2とラベル3の2つのラベルについて予測する場合を考えてみましょう。\n",
    "\n",
    "あるデータに対して以下のような確率が得られていれば，ラベル2がより尤もらしいと考えられます。\n",
    "\n",
    "- ラベル2である確率: 0.7\n",
    "- ラベル3である確率: 0.2\n",
    "\n",
    "これは ``np.where`` 関数によって以下のように実装できます。(別の方法を使っても構いません)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2_ex = np.array([0.7])\n",
    "pred_3_ex = np.array([0.2])\n",
    "\n",
    "pred_test_ex = np.where((pred_2_ex > pred_3_ex), 2, 3)\n",
    "print(f'Prediction: {pred_test_ex}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この方法は，そのまま複数データに拡張することができます。\n",
    "\n",
    "第二のデータについて各ラベルの確率が以下のような場合，ラベル3がより尤もらしいと考えられます。\n",
    "\n",
    "- ラベル2である確率: 0.1\n",
    "- ラベル3である確率: 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2_ex = np.array([0.7, 0.1])\n",
    "pred_3_ex = np.array([0.2, 0.6])\n",
    "\n",
    "pred_test_ex = np.where((pred_2_ex > pred_3_ex), 2, 3)\n",
    "print(f'Prediction: {pred_test_ex}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この方法は，3クラス分類の予測を行うためにも拡張することができます。  \n",
    "この拡張手法を実装し，最終的な3クラス分類の予測を行ってください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# Provide your code here\n",
    "\n",
    "pred_test = \n",
    "\n",
    "\n",
    "\n",
    "##############################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 提出\n",
    "</div>\n",
    "    \n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<b>Challenge 3c</b> \n",
    "\n",
    "**提出**: 以下の11個を提出してください。\n",
    "- **pred_test**: 公開テストデータに対する予測\n",
    "- **sample_train**: カーネル行列を計算するための訓練データ\n",
    "- **standard_scaler**: 標準化に用いたスケーラー\n",
    "- **pca**: 次元圧縮するために用いたPCA\n",
    "- **min_max_scaler**: 正規化に用いたスケーラー\n",
    "- **kernel_0**: 「ラベル0 vs それ以外」の二値分類に用いた``QuantumKernel``\n",
    "- **kernel_2**: 「ラベル2 vs それ以外」の二値分類に用いた``QuantumKernel``\n",
    "- **kernel_3**: 「ラベル3 vs それ以外」の二値分類に用いた``QuantumKernel``\n",
    "- **svc_0**: 「ラベル0 vs それ以外」の二値分類に用いた``SVC``\n",
    "- **svc_2**: 「ラベル0 vs それ以外」の二値分類に用いた``SVC``\n",
    "- **svc_3**: 「ラベル0 vs それ以外」の二値分類に用いた``SVC``\n",
    "\n",
    "**合格基準**: 公開テストデータと非公開テストデータ両方に対して70%以上の正解率\n",
    "\n",
    "**スコア**: 合格基準を超えた解答は以下のようにして採点されます。このスコアは小さいほど良いことを表します。\n",
    "    \n",
    "1. 各特徴マップを以下の設定でトランスパイルします。\n",
    "    - basis_gates=['u1', 'u2', 'u3', 'cx']\n",
    "    - optimization_level=0\n",
    "2. 各トランスパイル済み回路のコストを以下のように計算します。  \n",
    "    cost = 10 * #cx + (#u1 + #u2 + #u3)\n",
    "3. 3つのコストの合計がスコアになります。\n",
    "\n",
    "</div>\n",
    "\n",
    "提出する予測は以下の形式になっている必要があります。\n",
    "- 公開テストデータ (**sample_test**) に対する予測\n",
    "- type: numpy.ndarray\n",
    "- shape: (20,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Sample prediction: {sample_pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 答えを確認して以下のコードで提出します\n",
    "from qc_grader import grade_ex3c\n",
    "grade_ex3c(pred_test, sample_train, \n",
    "           standard_scaler, pca, min_max_scaler,\n",
    "           kernel_0, kernel_2, kernel_3,\n",
    "           svc_0, svc_2, svc_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional information\n",
    "\n",
    "**Created by:** Shota Nakasuji, Anna Phan\n",
    "\n",
    "**Version:** 1.0.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
